#!/usr/bin/env python3
"""
TaaOS AI Assistant - Advanced Features
Sentiment analysis, code generation, automated testing, and more
"""

import subprocess
import requests
import json
import os
from typing import Dict, List, Optional
from datetime import datetime

class AdvancedAI:
    """Advanced AI capabilities for TaaOS"""
    
    def __init__(self):
        self.ollama_url = "http://localhost:11434/api/generate"
        self.models = {
            'general': 'llama3:latest',
            'code': 'codellama:latest',
            'vision': 'llava:latest'
        }
    
    def analyze_sentiment(self, text: str) -> Dict:
        """Analyze sentiment of text"""
        prompt = f"""Analyze the sentiment of this text and provide:
1. Overall sentiment (positive/negative/neutral)
2. Confidence score (0-100)
3. Key emotions detected
4. Brief explanation

Text: {text}

Format your response as JSON."""
        
        response = self.query_llm('general', prompt)
        
        try:
            # Extract JSON from response
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except:
            pass
        
        return {'sentiment': 'neutral', 'confidence': 50, 'emotions': [], 'explanation': response}
    
    def generate_code(self, description: str, language: str = 'python') -> str:
        """Generate code from natural language description"""
        prompt = f"""Generate {language} code for the following task:

{description}

Requirements:
- Production-ready code
- Include error handling
- Add comments
- Follow best practices
- Include example usage

Provide only the code, no explanations."""
        
        return self.query_llm('code', prompt)
    
    def review_code(self, code: str, language: str = 'python') -> Dict:
        """Review code and provide suggestions"""
        prompt = f"""Review this {language} code and provide:
1. Security issues
2. Performance improvements
3. Best practice violations
4. Bug potential
5. Refactoring suggestions

Code:
```{language}
{code}
```

Format as JSON with categories."""
        
        response = self.query_llm('code', prompt)
        
        try:
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except:
            pass
        
        return {'review': response}
    
    def generate_tests(self, code: str, language: str = 'python') -> str:
        """Generate unit tests for code"""
        test_frameworks = {
            'python': 'pytest',
            'javascript': 'jest',
            'rust': 'cargo test',
            'go': 'testing'
        }
        
        framework = test_frameworks.get(language, 'pytest')
        
        prompt = f"""Generate comprehensive unit tests for this {language} code using {framework}:

```{language}
{code}
```

Include:
- Happy path tests
- Edge cases
- Error handling tests
- Mock external dependencies

Provide complete test code."""
        
        return self.query_llm('code', prompt)
    
    def explain_error(self, error_message: str, context: str = '') -> Dict:
        """Explain error and provide solution"""
        prompt = f"""Analyze this error and provide:
1. What caused the error
2. How to fix it
3. How to prevent it in the future
4. Exact commands or code to fix

Error: {error_message}

Context: {context}

Format as JSON."""
        
        response = self.query_llm('general', prompt)
        
        try:
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except:
            pass
        
        return {'explanation': response}
    
    def optimize_query(self, query: str, database: str = 'postgresql') -> str:
        """Optimize database query"""
        prompt = f"""Optimize this {database} query:

{query}

Provide:
1. Optimized query
2. Explanation of changes
3. Expected performance improvement
4. Index suggestions"""
        
        return self.query_llm('code', prompt)
    
    def generate_documentation(self, code: str, language: str = 'python') -> str:
        """Generate documentation for code"""
        prompt = f"""Generate comprehensive documentation for this {language} code:

```{language}
{code}
```

Include:
- Overview
- Parameters
- Return values
- Examples
- Notes/warnings

Use proper docstring format for {language}."""
        
        return self.query_llm('code', prompt)
    
    def suggest_architecture(self, requirements: str) -> Dict:
        """Suggest system architecture"""
        prompt = f"""Based on these requirements, suggest a system architecture:

{requirements}

Provide:
1. Recommended tech stack
2. Architecture diagram (as text)
3. Database schema suggestions
4. API design
5. Deployment strategy
6. Scalability considerations

Format as JSON."""
        
        response = self.query_llm('general', prompt)
        
        try:
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except:
            pass
        
        return {'architecture': response}
    
    def translate_code(self, code: str, from_lang: str, to_lang: str) -> str:
        """Translate code between languages"""
        prompt = f"""Translate this {from_lang} code to {to_lang}:

```{from_lang}
{code}
```

Maintain:
- Same functionality
- Idiomatic {to_lang} style
- Best practices for {to_lang}
- Comments

Provide only the translated code."""
        
        return self.query_llm('code', prompt)
    
    def analyze_logs(self, logs: str) -> Dict:
        """Analyze system logs for issues"""
        prompt = f"""Analyze these system logs and identify:
1. Errors and warnings
2. Patterns
3. Potential issues
4. Recommended actions

Logs:
{logs[:2000]}

Format as JSON."""
        
        response = self.query_llm('general', prompt)
        
        try:
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except:
            pass
        
        return {'analysis': response}
    
    def query_llm(self, model_type: str, prompt: str) -> str:
        """Query Ollama LLM"""
        try:
            model = self.models.get(model_type, 'llama3:latest')
            
            response = requests.post(
                self.ollama_url,
                json={
                    'model': model,
                    'prompt': prompt,
                    'stream': False,
                    'options': {
                        'temperature': 0.7,
                        'top_p': 0.9
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                return response.json()['response']
            else:
                return f"Error: {response.status_code}"
        except Exception as e:
            return f"Error querying LLM: {e}"

# CLI Interface
if __name__ == '__main__':
    import sys
    
    ai = AdvancedAI()
    
    if len(sys.argv) < 2:
        print("TaaOS Advanced AI Assistant")
        print("\nUsage:")
        print("  taaos-ai sentiment <text>")
        print("  taaos-ai generate <description> [language]")
        print("  taaos-ai review <file> [language]")
        print("  taaos-ai test <file> [language]")
        print("  taaos-ai explain-error <error>")
        print("  taaos-ai optimize-query <query> [database]")
        print("  taaos-ai docs <file> [language]")
        print("  taaos-ai translate <file> <from> <to>")
        print("  taaos-ai analyze-logs <logfile>")
        sys.exit(1)
    
    command = sys.argv[1]
    
    if command == 'sentiment':
        text = ' '.join(sys.argv[2:])
        result = ai.analyze_sentiment(text)
        print(json.dumps(result, indent=2))
    
    elif command == 'generate':
        description = ' '.join(sys.argv[2:])
        language = sys.argv[3] if len(sys.argv) > 3 else 'python'
        code = ai.generate_code(description, language)
        print(code)
    
    elif command == 'review':
        with open(sys.argv[2], 'r') as f:
            code = f.read()
        language = sys.argv[3] if len(sys.argv) > 3 else 'python'
        review = ai.review_code(code, language)
        print(json.dumps(review, indent=2))
    
    elif command == 'test':
        with open(sys.argv[2], 'r') as f:
            code = f.read()
        language = sys.argv[3] if len(sys.argv) > 3 else 'python'
        tests = ai.generate_tests(code, language)
        print(tests)
    
    elif command == 'explain-error':
        error = ' '.join(sys.argv[2:])
        explanation = ai.explain_error(error)
        print(json.dumps(explanation, indent=2))
    
    elif command == 'docs':
        with open(sys.argv[2], 'r') as f:
            code = f.read()
        language = sys.argv[3] if len(sys.argv) > 3 else 'python'
        docs = ai.generate_documentation(code, language)
        print(docs)
    
    elif command == 'analyze-logs':
        with open(sys.argv[2], 'r') as f:
            logs = f.read()
        analysis = ai.analyze_logs(logs)
        print(json.dumps(analysis, indent=2))
